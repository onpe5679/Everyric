import os
import sys
import torch
from typing import List, Dict, Optional, Tuple
import tempfile
import json

# ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.logger import setup_logger, log_step

logger = setup_logger(__name__)

def transcribe_audio_with_whisperx(
    audio_path: str,
    device: str = "auto",
    model_name: str = "large-v3",
    *,
    batch_size: int = 16,
    compute_type: str = "float16",
    language: Optional[str] = None,
    min_speakers: Optional[int] = None,
    max_speakers: Optional[int] = None,
    max_segment_duration: Optional[float] = None,
) -> List[Dict]:
    """
    WhisperX ê¸°ë°˜ ì •ë°€ ìŒì„± ì¸ì‹ ë° ë‹¨ì–´ ë‹¨ìœ„ íƒ€ì´ë° ì¶”ì¶œ
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        device: ì²˜ë¦¬ ì¥ì¹˜ ("auto", "cuda", "cpu")
        model_name: Whisper ëª¨ë¸ëª…
        batch_size: ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)
        compute_type: ì—°ì‚° ì •ë°€ë„ ("float16", "int8", "float32")
        language: ì–¸ì–´ ì½”ë“œ (Noneì´ë©´ ìë™ ê°ì§€)
        min_speakers: ìµœì†Œ í™”ì ìˆ˜ (í™”ì ë¶„ë¦¬ìš©)
        max_speakers: ìµœëŒ€ í™”ì ìˆ˜ (í™”ì ë¶„ë¦¬ìš©)
    
    Returns:
        List of segments with precise word-level timing
    """
    try:
        # cuDNN ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        import os
        
        # cuDNN DLLì„ ì§ì ‘ ì°¾ì•„ì„œ PATHì— ì¶”ê°€
        import glob
        
        # ê°€ëŠ¥í•œ cuDNN ì„¤ì¹˜ ê²½ë¡œë“¤
        search_paths = [
            r"C:\Program Files\NVIDIA\CUDNN",
            r"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\*\bin",
            r"C:\tools\cuda",
            r"C:\cuda"
        ]
        
        cudnn_dll_found = False
        current_path = os.environ.get("PATH", "")
        
        for search_path in search_paths:
            # ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ í™•ì¥
            if '*' in search_path:
                expanded_paths = glob.glob(search_path)
            else:
                expanded_paths = [search_path]
            
            for base_path in expanded_paths:
                if not os.path.exists(base_path):
                    continue
                    
                # bin í´ë”ì™€ lib í´ë” ëª¨ë‘ í™•ì¸
                for subdir in ['bin', 'lib', '']:
                    dll_path = os.path.join(base_path, subdir) if subdir else base_path
                    if os.path.exists(dll_path):
                        # cudnn_ops_infer64_8.dll íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
                        dll_files = glob.glob(os.path.join(dll_path, "cudnn_ops_infer64_*.dll"))
                        if dll_files and dll_path not in current_path:
                            os.environ["PATH"] = f"{dll_path};{current_path}"
                            logger.info(f"âœ… cuDNN DLL ê²½ë¡œë¥¼ PATHì— ì¶”ê°€: {dll_path}")
                            current_path = os.environ["PATH"]
                            cudnn_dll_found = True
        
        if not cudnn_dll_found:
            logger.warning("âš ï¸ cuDNN DLLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GPU ì„±ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì¶”ê°€ CUDA í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
        
        import whisperx
    except ImportError:
        logger.error("WhisperXê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.error("ì„¤ì¹˜ ë°©ë²•:")
        logger.error("  pip install whisperx")
        logger.error("  ë˜ëŠ”")
        logger.error("  pip install git+https://github.com/m-bain/whisperx.git")
        raise ImportError("WhisperX not installed")

    logger.info(f"ğŸ” WhisperXë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì‹œì‘: {audio_path}")
    logger.info(f"ğŸ¤– ì‚¬ìš©í•  WhisperX ëª¨ë¸: {model_name}")
    
    # ì¥ì¹˜ ì„¤ì •
    if device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    logger.info(f"âš™ï¸ ì²˜ë¦¬ ì¥ì¹˜: {device}")
    logger.info(f"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {batch_size}, ì—°ì‚° ì •ë°€ë„: {compute_type}")

    try:
        # 1ë‹¨ê³„: Whisper ëª¨ë¸ ë¡œë“œ ë° ì „ì‚¬
        with log_step("WhisperX ëª¨ë¸ ë¡œë“œ", logger):
            try:
                model = whisperx.load_model(
                    model_name, 
                    device, 
                    compute_type=compute_type,
                    language=language
                )
                logger.info("âœ… WhisperX ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                if "cudnn" in str(e).lower():
                    logger.warning(f"cuDNN ì˜¤ë¥˜ ë°œìƒ, CPUë¡œ í´ë°±: {e}")
                    device = "cpu"
                    compute_type = "float32"
                    model = whisperx.load_model(
                        model_name, 
                        device, 
                        compute_type=compute_type,
                        language=language
                    )
                    logger.info("âœ… WhisperX ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (CPU ëª¨ë“œ)")
                else:
                    raise

        with log_step("ìŒì„± ì „ì‚¬", logger):
            logger.info("ğŸ¯ WhisperXë¡œ ìŒì„± ì „ì‚¬ ì¤‘...")
            audio = whisperx.load_audio(audio_path)
            result = model.transcribe(audio, batch_size=batch_size)
            logger.info(f"âœ… ì „ì‚¬ ì™„ë£Œ. ì–¸ì–´: {result.get('language', 'unknown')}")

        # 2ë‹¨ê³„: ì •ë ¬ ëª¨ë¸ ë¡œë“œ ë° ë‹¨ì–´ ë‹¨ìœ„ íƒ€ì´ë° ì¶”ì¶œ
        with log_step("ë‹¨ì–´ ë‹¨ìœ„ ì •ë ¬", logger):
            try:
                model_a, metadata = whisperx.load_align_model(
                    language_code=result["language"], 
                    device=device
                )
                result = whisperx.align(
                    result["segments"], 
                    model_a, 
                    metadata, 
                    audio, 
                    device, 
                    return_char_alignments=False
                )
                logger.info("âœ… ë‹¨ì–´ ë‹¨ìœ„ ì •ë ¬ ì™„ë£Œ")
            except Exception as e:
                if "cudnn" in str(e).lower() or "cuda" in str(e).lower():
                    logger.warning(f"ì •ë ¬ ë‹¨ê³„ì—ì„œ CUDA ì˜¤ë¥˜ ë°œìƒ, CPUë¡œ ì¬ì‹œë„: {e}")
                    model_a, metadata = whisperx.load_align_model(
                        language_code=result["language"], 
                        device="cpu"
                    )
                    result = whisperx.align(
                        result["segments"], 
                        model_a, 
                        metadata, 
                        audio, 
                        "cpu", 
                        return_char_alignments=False
                    )
                    logger.info("âœ… ë‹¨ì–´ ë‹¨ìœ„ ì •ë ¬ ì™„ë£Œ (CPU ëª¨ë“œ)")
                else:
                    logger.warning(f"ì •ë ¬ ì‹¤íŒ¨, ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©: {e}")
                    # ì •ë ¬ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ë§Œ ì‚¬ìš©

        # 3ë‹¨ê³„: í™”ì ë¶„ë¦¬ (ì„ íƒì )
        if min_speakers is not None or max_speakers is not None:
            with log_step("í™”ì ë¶„ë¦¬", logger):
                try:
                    diarize_model = whisperx.DiarizationPipeline(
                        use_auth_token=None,  # HuggingFace í† í°ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
                        device=device
                    )
                    diarize_segments = diarize_model(
                        audio, 
                        min_speakers=min_speakers, 
                        max_speakers=max_speakers
                    )
                    result = whisperx.assign_word_speakers(diarize_segments, result)
                    logger.info("âœ… í™”ì ë¶„ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"í™”ì ë¶„ë¦¬ ì‹¤íŒ¨ (ì„ íƒì  ê¸°ëŠ¥): {e}")

        # ê²°ê³¼ ë³€í™˜: WhisperX í˜•ì‹ì„ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        segments = []
        for seg in result.get("segments", []):
            segment = {
                "start": float(seg.get("start", 0.0)),
                "end": float(seg.get("end", 0.0)),
                "text": seg.get("text", "").strip(),
            }
            
            # ë‹¨ì–´ ë‹¨ìœ„ ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            if "words" in seg:
                segment["words"] = []
                for word in seg["words"]:
                    word_info = {
                        "word": word.get("word", ""),
                        "start": float(word.get("start", 0.0)),
                        "end": float(word.get("end", 0.0)),
                        "score": float(word.get("score", 0.0)),
                    }
                    if "speaker" in word:
                        word_info["speaker"] = word["speaker"]
                    segment["words"].append(word_info)
            
            if "speaker" in seg:
                segment["speaker"] = seg["speaker"]
                
            segments.append(segment)

        logger.info(f"âœ… WhisperX ìŒì„± ì¸ì‹ ì™„ë£Œ. {len(segments)}ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # ë‹¨ì–´ ë‹¨ìœ„ íƒ€ì´ë° í’ˆì§ˆ ê²€ì¦
        word_count = sum(len(seg.get("words", [])) for seg in segments)
        if word_count > 0:
            logger.info(f"ğŸ“ ë‹¨ì–´ ë‹¨ìœ„ íƒ€ì´ë°: {word_count}ê°œ ë‹¨ì–´")
        
        # ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì œí•œì´ ì„¤ì •ëœ ê²½ìš° ë¶„í•  ì ìš©
        if max_segment_duration and max_segment_duration > 0:
            try:
                segments = _split_long_segments(segments, max_segment_duration)
                logger.info(f"âœ‚ï¸ ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì ìš©(max {max_segment_duration:.2f}s): ì´ {len(segments)}ê°œ")
            except Exception as e:
                logger.warning(f"ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì¤‘ ì˜¤ë¥˜: {e}")
        return segments
        
    except Exception as e:
        logger.error(f"âŒ WhisperX ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise

def _get_device(device_preference: str) -> str:
    """ìµœì ì˜ ì¥ì¹˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
    if device_preference == "auto":
        if torch.cuda.is_available():
            device = "cuda"
            logger.info(f"ğŸš€ CUDA GPU ê°ì§€ë¨! GPUë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. (GPU ê°œìˆ˜: {torch.cuda.device_count()})")
        else:
            device = "cpu"
            logger.info("ğŸ’» GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    elif device_preference == "cuda":
        if torch.cuda.is_available():
            device = "cuda"
            logger.info(f"ğŸš€ GPU ê°•ì œ ì‚¬ìš© ëª¨ë“œ. (GPU ê°œìˆ˜: {torch.cuda.device_count()})")
        else:
            logger.warning("âš ï¸ CUDA GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ í´ë°±í•©ë‹ˆë‹¤.")
            device = "cpu"
    else:
        device = "cpu"
        logger.info("ğŸ’» CPU ì‚¬ìš© ëª¨ë“œ")
    
    return device

def _split_long_segments(segments: List[Dict], max_duration: float) -> List[Dict]:
    """
    ì„¸ê·¸ë¨¼íŠ¸ê°€ max_durationì„ ì´ˆê³¼í•˜ë©´ ë‹¨ì–´ ê²½ê³„(ê°€ëŠ¥í•˜ë©´)ì— ë§ì¶° ë¶„í• í•©ë‹ˆë‹¤.
    ë‹¨ì–´ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê· ë“± ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    """
    import math
    new_segments: List[Dict] = []
    for seg in segments:
        start = float(seg.get('start', 0.0))
        end = float(seg.get('end', 0.0))
        text = seg.get('text', '')
        words = seg.get('words', []) or []
        duration = max(0.0, end - start)
        if duration <= max_duration or end <= start:
            new_segments.append(seg)
            continue

        if words:
            # ë‹¨ì–´ ê²½ê³„ ê¸°ì¤€ìœ¼ë¡œ ìŠ¬ë¼ì´ìŠ¤
            bucket: List[Dict] = []
            bucket_start = None
            for w in words:
                w_s = float(w.get('start', start))
                w_e = float(w.get('end', w_s))
                if bucket_start is None:
                    bucket_start = w_s
                bucket.append(w)
                if (w_e - bucket_start) >= max_duration:
                    # flush bucket
                    chunk_text = ' '.join((wi.get('word') or '').strip() for wi in bucket).strip()
                    chunk = {
                        'start': bucket_start,
                        'end': w_e,
                        'text': chunk_text or text,
                        'words': list(bucket),
                    }
                    new_segments.append(chunk)
                    bucket = []
                    bucket_start = None
            if bucket:
                chunk_text = ' '.join((wi.get('word') or '').strip() for wi in bucket).strip()
                chunk = {
                    'start': bucket_start if bucket_start is not None else start,
                    'end': float(bucket[-1].get('end', end)),
                    'text': chunk_text or text,
                    'words': list(bucket),
                }
                new_segments.append(chunk)
        else:
            # ê· ë“± ë¶„í• 
            parts = max(1, math.ceil(duration / max_duration))
            chunk_len = duration / parts
            for i in range(parts):
                c_s = start + i * chunk_len
                c_e = min(end, c_s + chunk_len)
                # í…ìŠ¤íŠ¸ë„ ëŒ€ëµ ê· ë“± ë¶„í• 
                if text and parts > 1:
                    n = len(text)
                    s_idx = int(i * n / parts)
                    e_idx = int((i + 1) * n / parts)
                    c_text = text[s_idx:e_idx].strip() or text
                else:
                    c_text = text
                new_segments.append({'start': c_s, 'end': c_e, 'text': c_text})
    return new_segments

def detect_silence_segments(audio_path: str, min_silence_len: float = 0.5, silence_thresh: float = -40.0) -> List[Tuple[float, float]]:
    """
    ì˜¤ë””ì˜¤ì—ì„œ ë¬´ì„± êµ¬ê°„ì„ ê°ì§€í•©ë‹ˆë‹¤.
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        min_silence_len: ìµœì†Œ ë¬´ì„± êµ¬ê°„ ê¸¸ì´ (ì´ˆ)
        silence_thresh: ë¬´ì„± íŒì • ì„ê³„ê°’ (dB)
    
    Returns:
        List of (start, end) tuples for silence segments
    """
    try:
        from pydub import AudioSegment
        from pydub.silence import detect_silence
    except ImportError:
        logger.warning("pydubê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë¬´ì„± êµ¬ê°„ ê°ì§€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        logger.info("ì„¤ì¹˜: pip install pydub")
        return []
    
    try:
        logger.info("ğŸ”‡ ë¬´ì„± êµ¬ê°„ ê°ì§€ ì‹œì‘...")
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_file(audio_path)
        
        # ë¬´ì„± êµ¬ê°„ ê°ì§€
        silence_segments = detect_silence(
            audio,
            min_silence_len=int(min_silence_len * 1000),  # ms ë‹¨ìœ„ë¡œ ë³€í™˜
            silence_thresh=silence_thresh
        )
        
        # ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
        silence_ranges = [(start/1000.0, end/1000.0) for start, end in silence_segments]
        
        logger.info(f"ğŸ”‡ {len(silence_ranges)}ê°œì˜ ë¬´ì„± êµ¬ê°„ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤.")
        
        return silence_ranges
        
    except Exception as e:
        logger.warning(f"ë¬´ì„± êµ¬ê°„ ê°ì§€ ì‹¤íŒ¨: {e}")
        return []

def apply_silence_based_timing_correction(segments: List[Dict], silence_ranges: List[Tuple[float, float]]) -> List[Dict]:
    """
    ë¬´ì„± êµ¬ê°„ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ íƒ€ì´ë°ì„ ë³´ì •í•©ë‹ˆë‹¤.
    """
    if not silence_ranges:
        return segments
    
    logger.info("ğŸ”§ ë¬´ì„± êµ¬ê°„ ê¸°ë°˜ íƒ€ì´ë° ë³´ì • ì ìš©...")
    
    corrected_segments = []
    
    for seg in segments:
        start = seg["start"]
        end = seg["end"]
        
        # ì„¸ê·¸ë¨¼íŠ¸ê°€ ë¬´ì„± êµ¬ê°„ê³¼ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
        overlapping_silence = []
        for sil_start, sil_end in silence_ranges:
            if not (end <= sil_start or start >= sil_end):  # ê²¹ì¹¨ ìˆìŒ
                overlap_start = max(start, sil_start)
                overlap_end = min(end, sil_end)
                overlapping_silence.append((overlap_start, overlap_end))
        
        # ê²¹ì¹˜ëŠ” ë¬´ì„± êµ¬ê°„ì´ ì„¸ê·¸ë¨¼íŠ¸ì˜ 50% ì´ìƒì´ë©´ íƒ€ì´ë° ì¡°ì •
        total_overlap = sum(oe - os for os, oe in overlapping_silence)
        segment_duration = end - start
        
        if segment_duration > 0 and total_overlap / segment_duration > 0.5:
            # ë¬´ì„± êµ¬ê°„ì„ í”¼í•´ íƒ€ì´ë° ì¡°ì •
            # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ë¬´ì„± êµ¬ê°„ ì§ì „/ì§í›„ë¡œ ì´ë™
            for sil_start, sil_end in silence_ranges:
                if start < sil_start < end:
                    seg["end"] = sil_start
                    break
                elif start < sil_end < end:
                    seg["start"] = sil_end
                    break
        
        corrected_segments.append(seg)
    
    return corrected_segments
