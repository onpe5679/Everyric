import whisper
import torch
from typing import List, Dict
import os
import sys
import re

# ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.logger import setup_logger, log_step

logger = setup_logger(__name__)

def _get_device(device_preference: str) -> str:
    """ìµœì ì˜ ì¥ì¹˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
    if device_preference == "auto":
        if torch.cuda.is_available():
            device = "cuda"
            logger.info(f"ğŸš€ CUDA GPU ê°ì§€ë¨! GPUë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. (GPU ê°œìˆ˜: {torch.cuda.device_count()})")
        else:
            device = "cpu"
            logger.info("ğŸ’» GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    elif device_preference == "cuda":
        if torch.cuda.is_available():
            device = "cuda"
            logger.info(f"ğŸš€ GPU ê°•ì œ ì‚¬ìš© ëª¨ë“œ. (GPU ê°œìˆ˜: {torch.cuda.device_count()})")
        else:
            logger.warning("âš ï¸ CUDA GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ í´ë°±í•©ë‹ˆë‹¤.")
            device = "cpu"
    else:
        device = "cpu"
        logger.info("ğŸ’» CPU ì‚¬ìš© ëª¨ë“œ")
    
    return device

def transcribe_audio(
    audio_path: str,
    device: str = "auto",
    model_name: str = "tiny",
    *,
    condition_on_previous_text: bool = False,
    temperature: float = 0.0,
    max_segment_duration: float = 6.0,
    split_on_punctuation: bool = True,
) -> List[Dict]:
    """
    openai-whisper ê¸°ë°˜ ìŒì„± ì¸ì‹ ë° íƒ€ì´ë° ì¶”ì¶œ
    Returns:
      List of segments, each with 'text', 'start', 'end'
    """
    logger.info(f"ğŸ” ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì‹œì‘: {audio_path}")
    logger.info(f"ğŸ¤– ì‚¬ìš©í•  Whisper ëª¨ë¸: {model_name}")
    
    # ìµœì  ì¥ì¹˜ ì„ íƒ
    actual_device = _get_device(device)
    
    # ëª¨ë¸ ë¡œë“œ
    with log_step("Whisper ëª¨ë¸ ë¡œë“œ", logger):
        try:
            model = whisper.load_model(model_name, device=actual_device)
            logger.info(f"âœ… ëª¨ë¸ì´ {actual_device}ì— ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            if actual_device == "cuda":
                logger.warning(f"âš ï¸ GPU ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                logger.info("ğŸ”„ CPUë¡œ í´ë°±í•©ë‹ˆë‹¤...")
                actual_device = "cpu"
                model = whisper.load_model(model_name, device=actual_device)
                logger.info("âœ… CPUì—ì„œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                raise
    
    # ìŒì„± ì¸ì‹ ì‹¤í–‰
    try:
        with log_step("ìŒì„± ì¸ì‹ ì‹¤í–‰", logger):
            logger.info("ğŸ¯ Whisper ëª¨ë¸ë¡œ ìŒì„± ë¶„ì„ ì¤‘... (ì§„í–‰ë¥ ì€ ë‚´ë¶€ì ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤)")
            result = model.transcribe(
                audio_path,
                verbose=True,  # Whisper ìì²´ ì§„í–‰ë¥  í‘œì‹œ í™œì„±í™”
                condition_on_previous_text=condition_on_previous_text,
                temperature=temperature,
                compression_ratio_threshold=2.4,
                logprob_threshold=-1.0,
                no_speech_threshold=0.6,
            )
        
        segments = result.get("segments", [])
        # ê³¼ë„í•˜ê²Œ ê¸´ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ë¬¸ì¥ë¶€í˜¸ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì‹œê°„ì„ ë¹„ë¡€ ë¶„ë°°
        if split_on_punctuation and segments:
            segments = _split_long_segments(segments, max_segment_duration)
        logger.info(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ. {len(segments)}ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        return segments
        
    except Exception as e:
        logger.error(f"âŒ ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise


def _split_long_segments(segments: List[Dict], max_duration: float) -> List[Dict]:
    """ì„¸ê·¸ë¨¼íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ë¬¸ì¥ë¶€í˜¸(.,!?/â€¦/ã€‚/ã€/ï¼/ï¼Ÿ/ãƒ»/â™ª/\n) ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê³ ,
    ê° ì¡°ê°ì˜ ë¬¸ì ë¹„ìœ¨ë¡œ ì‹œê°„ì„ ë¶„ë°°í•©ë‹ˆë‹¤."""
    punct_pattern = re.compile(r"([ã€‚ï¼\.ã€ï¼Œ,ï¼!ï¼Ÿ\?â€¦ãƒ»â™ª\n])")
    out: List[Dict] = []
    for seg in segments:
        start = float(seg.get("start", 0.0))
        end = float(seg.get("end", start))
        text = (seg.get("text") or "").strip()
        duration = max(0.0, end - start)

        if duration <= max_duration or not text:
            out.append(seg)
            continue

        # ë¬¸ì¥ë¶€í˜¸ ë³´ì¡´ ë¶„í• : êµ¬ë¶„ìë„ í† í°ìœ¼ë¡œ ìœ ì§€ í›„ ì¬ê²°í•©
        parts = [t for t in punct_pattern.split(text) if t is not None and t != ""]
        # êµ¬ë¶„ìê¹Œì§€ í•©ì³ ë¬¸ì¥ ë‹¨ìœ„ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        sentences: List[str] = []
        buf = ""
        for token in parts:
            buf += token
            if punct_pattern.fullmatch(token):
                sentences.append(buf.strip())
                buf = ""
        if buf.strip():
            sentences.append(buf.strip())

        total_chars = sum(len(s) for s in sentences) or 1
        # ìµœì†Œ 1ë¬¸ì¥ ë³´ì¥
        cur = start
        for i, s in enumerate(sentences):
            frac = len(s) / total_chars
            seg_dur = duration * frac
            # ê²½ê³„ ëˆ„ì  ì˜¤ì°¨ ìµœì†Œí™”: ë§ˆì§€ë§‰ ë¬¸ì¥ì€ endì— ìŠ¤ëƒ…
            seg_start = cur
            seg_end = end if i == len(sentences) - 1 else min(end, cur + seg_dur)
            cur = seg_end
            if s:
                out.append({
                    "start": float(seg_start),
                    "end": float(seg_end),
                    "text": s,
                })
    return out
