import logging
from typing import List, Dict, Tuple
import re
from .phonetic_matcher import PhoneticMatcher

logger = logging.getLogger(__name__)

class SmartAligner:
    """Whisper ìŒì„± ì¸ì‹ ê²°ê³¼ì™€ ì›ë³¸ ê°€ì‚¬ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ì •ë ¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, max_segment_length: int = 100, alignment_config: dict = None):
        """
        Args:
            max_segment_length: ê° ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ì˜ ìµœëŒ€ ë¬¸ì ê¸¸ì´ (ê¸°ë³¸ê°’: 100)
            alignment_config: ì •ë ¬ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.logger = logger
        self.phonetic_matcher = PhoneticMatcher()
        self.max_segment_length = max_segment_length
        
        # ì„¤ì • ê¸°ë³¸ê°’
        default_config = {
            "similarity_threshold": 0.15,
            "max_segment_combinations": 5,
            "enable_sequential_fallback": True,
            "split_long_segments": True,
            "time_distribution_method": "character_based"
        }
        
        self.config = {**default_config, **(alignment_config or {})}
        
    def align_lyrics_with_timing(self, lyrics: List[str], whisper_segments: List[Dict]) -> List[Dict]:
        """
        ì›ë³¸ ê°€ì‚¬ì™€ Whisper ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì •ë ¬í•˜ì—¬ ì •í™•í•œ íƒ€ì´ë° ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            lyrics: ì›ë³¸ ê°€ì‚¬ ë¼ì¸ ë¦¬ìŠ¤íŠ¸
            whisper_segments: Whisper ìŒì„± ì¸ì‹ ê²°ê³¼ ì„¸ê·¸ë¨¼íŠ¸
            
        Returns:
            ì •ë ¬ëœ ê°€ì‚¬-íƒ€ì´ë° ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        self.logger.info(f"ğŸ”„ ìŠ¤ë§ˆíŠ¸ ì •ë ¬ ì‹œì‘ - ê°€ì‚¬: {len(lyrics)}ì¤„, ì„¸ê·¸ë¨¼íŠ¸: {len(whisper_segments)}ê°œ")
        
        # 1. ê°€ì‚¬ì™€ Whisper í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        processed_lyrics = self._preprocess_lyrics(lyrics)
        processed_segments = self._preprocess_segments(whisper_segments)
        
        # 2. ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë§¤ì¹­
        alignment_map = self._create_alignment_map(processed_lyrics, processed_segments)
        
        # 3. íƒ€ì´ë° ì •ë³´ í• ë‹¹
        aligned_result = self._assign_timing(lyrics, whisper_segments, alignment_map)
        
        self.logger.info(f"âœ… ì •ë ¬ ì™„ë£Œ - {len(aligned_result)}ê°œì˜ íƒ€ì´ë° ê°€ì‚¬ ìƒì„±")
        return aligned_result
    
    def _preprocess_lyrics(self, lyrics: List[str]) -> List[str]:
        """ê°€ì‚¬ ì „ì²˜ë¦¬ - íŠ¹ìˆ˜ë¬¸ì ì œê±°, ê³µë°± ì •ë¦¬"""
        processed = []
        for lyric in lyrics:
            # íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì†Œë¬¸ì ë³€í™˜, ê³µë°± ì •ë¦¬
            clean = re.sub(r'[^\w\sê°€-í£ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯]', '', lyric)
            clean = re.sub(r'\s+', ' ', clean).strip().lower()
            if clean:
                processed.append(clean)
        return processed
    
    def _preprocess_segments(self, segments: List[Dict]) -> List[str]:
        """Whisper ì„¸ê·¸ë¨¼íŠ¸ ì „ì²˜ë¦¬"""
        processed = []
        for segment in segments:
            text = segment.get('text', '').strip()
            # íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì†Œë¬¸ì ë³€í™˜, ê³µë°± ì •ë¦¬
            clean = re.sub(r'[^\w\sê°€-í£ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯]', '', text)
            clean = re.sub(r'\s+', ' ', clean).strip().lower()
            if clean:
                processed.append(clean)
        return processed
    
    def _create_alignment_map(self, lyrics: List[str], segments: List[str]) -> List[Tuple[int, List[int]]]:
        """
        ê°€ì‚¬ ë¼ì¸ê³¼ ì„¸ê·¸ë¨¼íŠ¸ ê°„ì˜ ë§¤í•‘ ìƒì„±
        
        Returns:
            [(lyric_index, [segment_indices]), ...] í˜•íƒœì˜ ë§¤í•‘
        """
        alignment_map = []
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_lyrics = ' '.join(lyrics)
        full_segments = ' '.join(segments)
        
        # ë°œìŒ ê¸°ë°˜ ë§¤ì¹­
        lyric_pos = 0
        segment_pos = 0
        
        for lyric_idx, lyric in enumerate(lyrics):
            # í˜„ì¬ ê°€ì‚¬ ë¼ì¸ì— í•´ë‹¹í•˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ë“¤ ì°¾ê¸°
            best_match_ratio = 0
            best_segments = []
            
            # ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•©ìœ¼ë¡œ ë§¤ì¹­ ì‹œë„
            for seg_count in range(1, min(self.config["max_segment_combinations"], len(segments) - segment_pos + 1)):
                if segment_pos + seg_count > len(segments):
                    break
                    
                combined_segments = ' '.join(segments[segment_pos:segment_pos + seg_count])
                # ë°œìŒ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
                ratio = self.phonetic_matcher.calculate_phonetic_similarity(lyric, combined_segments)
                
                if ratio > best_match_ratio:
                    best_match_ratio = ratio
                    best_segments = list(range(segment_pos, segment_pos + seg_count))
            
            # ë§¤ì¹­ ê²°ê³¼ ì €ì¥ (ì„¤ì • ê¸°ë°˜ ì„ê³„ê°’ ì ìš©)
            if best_segments and best_match_ratio > self.config["similarity_threshold"]:
                alignment_map.append((lyric_idx, best_segments))
                segment_pos = max(best_segments) + 1
            else:
                # ìˆœì°¨ì  í´ë°± ì„¤ì •ì´ í™œì„±í™”ëœ ê²½ìš°
                if self.config["enable_sequential_fallback"]:
                    if segment_pos < len(segments):
                        alignment_map.append((lyric_idx, [segment_pos]))
                        segment_pos += 1
                    else:
                        # ì„¸ê·¸ë¨¼íŠ¸ê°€ ë¶€ì¡±í•œ ê²½ìš° ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¬ì‚¬ìš©
                        if len(segments) > 0:
                            alignment_map.append((lyric_idx, [len(segments) - 1]))
                        else:
                            alignment_map.append((lyric_idx, []))
                else:
                    alignment_map.append((lyric_idx, []))
        
        return alignment_map
    
    def _assign_timing(self, original_lyrics: List[str], segments: List[Dict], 
                      alignment_map: List[Tuple[int, List[int]]]) -> List[Dict]:
        """ë§¤í•‘ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íƒ€ì´ë° í• ë‹¹ (ìµœëŒ€ ê¸¸ì´ ì œí•œ ì ìš©)"""
        result = []
        
        for lyric_idx, segment_indices in alignment_map:
            if not segment_indices:
                # ë§¤ì¹­ëœ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ëŠ” ê²½ìš°
                result.append({
                    'start': 0.0,
                    'end': 0.0,
                    'text': original_lyrics[lyric_idx],
                    'confidence': 0.0
                })
                continue
            
            # ë§¤ì¹­ëœ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì˜ íƒ€ì´ë° ì •ë³´ ê²°í•©
            start_time = segments[segment_indices[0]]['start']
            end_time = segments[segment_indices[-1]]['end']
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ë§¤ì¹­ëœ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ì™€ ìœ ì‚¬ë„ ê¸°ë°˜)
            confidence = min(1.0, len(segment_indices) / 3.0)
            
            lyric_text = original_lyrics[lyric_idx]
            
            # ìµœëŒ€ ê¸¸ì´ ì œí•œ ì ìš© (ì„¤ì • ê¸°ë°˜)
            if not self.config["split_long_segments"] or len(lyric_text) <= self.max_segment_length:
                # ê¸¸ì´ê°€ ì œí•œ ë‚´ì´ê±°ë‚˜ ë¶„í•  ë¹„í™œì„±í™”ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì¶”ê°€
                result.append({
                    'start': start_time,
                    'end': end_time,
                    'text': lyric_text,
                    'confidence': confidence,
                    'matched_segments': segment_indices
                })
            else:
                # ê¸¸ì´ê°€ ì œí•œì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš° ë¶„í• 
                split_segments = self._split_long_text(
                    lyric_text, start_time, end_time, confidence, segment_indices
                )
                result.extend(split_segments)
                self.logger.debug(f"ê¸´ í…ìŠ¤íŠ¸ ë¶„í• : '{lyric_text[:30]}...' â†’ {len(split_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
            
            # ë””ë²„ê·¸ ì •ë³´
            if lyric_idx < 5 or lyric_idx >= len(original_lyrics) - 5:
                matched_texts = [segments[i].get('text', '') for i in segment_indices]
                self.logger.debug(f"ì •ë ¬ {lyric_idx+1}: '{original_lyrics[lyric_idx][:30]}...' â†’ "
                                f"ì„¸ê·¸ë¨¼íŠ¸ {segment_indices} (ì‹ ë¢°ë„: {confidence:.2f})")
        
        return result
    
    def _split_long_text(self, text: str, start_time: float, end_time: float, 
                        confidence: float, segment_indices: List[int]) -> List[Dict]:
        """
        ê¸´ í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€ ê¸¸ì´ ì œí•œì— ë§ê²Œ ë¶„í• í•©ë‹ˆë‹¤.
        
        Args:
            text: ë¶„í• í•  í…ìŠ¤íŠ¸
            start_time: ì‹œì‘ ì‹œê°„
            end_time: ì¢…ë£Œ ì‹œê°„
            confidence: ì‹ ë¢°ë„
            segment_indices: ë§¤ì¹­ëœ ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤ë“¤
            
        Returns:
            ë¶„í• ëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        segments = []
        total_duration = end_time - start_time
        
        # ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• ì  ì°¾ê¸° (ê³µë°±, ì‰¼í‘œ, ë§ˆì¹¨í‘œ ë“±)
        split_points = self._find_natural_split_points(text)
        
        # ë¶„í• ì ì„ ê¸°ì¤€ìœ¼ë¡œ ì²­í¬ ìƒì„±
        chunks = self._create_chunks_from_split_points(text, split_points)
        
        # ê° ì²­í¬ì— ì‹œê°„ í• ë‹¹ (ì„¤ì • ê¸°ë°˜ ì‹œê°„ ë¶„ë°°)
        if self.config["time_distribution_method"] == "character_based":
            # ë¬¸ì ìˆ˜ ê¸°ë°˜ ë¶„ë°°
            total_chars = sum(len(chunk.strip()) for chunk in chunks if chunk.strip())
            current_time = start_time
            
            for i, chunk in enumerate(chunks):
                if not chunk.strip():
                    continue
                    
                chunk_chars = len(chunk.strip())
                chunk_duration = (total_duration * chunk_chars / total_chars) if total_chars > 0 else (total_duration / len(chunks))
                
                chunk_start = current_time
                chunk_end = current_time + chunk_duration
                current_time = chunk_end
                
                segments.append({
                    'start': chunk_start,
                    'end': chunk_end,
                    'text': chunk.strip(),
                    'confidence': confidence * 0.8,
                    'matched_segments': segment_indices,
                    'is_split': True
                })
        else:
            # ê· ë“± ë¶„ë°° (ê¸°ë³¸ê°’)
            current_time = start_time
            chunk_duration = total_duration / len(chunks)
            
            for i, chunk in enumerate(chunks):
                if not chunk.strip():
                    continue
                    
                chunk_start = current_time
                chunk_end = current_time + chunk_duration
                current_time = chunk_end
                
                segments.append({
                    'start': chunk_start,
                    'end': chunk_end,
                    'text': chunk.strip(),
                    'confidence': confidence * 0.8,  # ë¶„í• ëœ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ì‹ ë¢°ë„ ì•½ê°„ ê°ì†Œ
                    'matched_segments': segment_indices,
                    'is_split': True
                })
        
        return segments
    
    def _find_natural_split_points(self, text: str) -> List[int]:
        """í…ìŠ¤íŠ¸ì—ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• ì ì„ ì°¾ìŠµë‹ˆë‹¤."""
        split_points = [0]  # ì‹œì‘ì 
        
        # ìš°ì„ ìˆœìœ„: ë§ˆì¹¨í‘œ > ì‰¼í‘œ > ê³µë°±
        separators = ['.', '!', '?', ',', ';', ' ']
        
        current_pos = 0
        while current_pos < len(text):
            # ìµœëŒ€ ê¸¸ì´ ë‚´ì—ì„œ ê°€ì¥ ì¢‹ì€ ë¶„í• ì  ì°¾ê¸°
            search_end = min(current_pos + self.max_segment_length, len(text))
            best_split = search_end
            
            # ë’¤ì—ì„œë¶€í„° ë¶„í• ì  ì°¾ê¸° (ë” ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• ì„ ìœ„í•´)
            for pos in range(search_end - 1, current_pos, -1):
                if text[pos] in separators:
                    best_split = pos + 1
                    break
            
            if best_split > current_pos:
                split_points.append(best_split)
                current_pos = best_split
            else:
                # ë¶„í• ì ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ê°•ì œ ë¶„í• 
                current_pos += self.max_segment_length
                if current_pos < len(text):
                    split_points.append(current_pos)
        
        if split_points[-1] != len(text):
            split_points.append(len(text))
        
        return split_points
    
    def _create_chunks_from_split_points(self, text: str, split_points: List[int]) -> List[str]:
        """ë¶„í• ì ì„ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        chunks = []
        for i in range(len(split_points) - 1):
            start = split_points[i]
            end = split_points[i + 1]
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
        return chunks

def align_lyrics_with_whisper(lyrics: List[str], whisper_segments: List[Dict]) -> List[Dict]:
    """í¸ì˜ í•¨ìˆ˜: ìŠ¤ë§ˆíŠ¸ ì •ë ¬ ì‹¤í–‰"""
    aligner = SmartAligner()
    return aligner.align_lyrics_with_timing(lyrics, whisper_segments)
